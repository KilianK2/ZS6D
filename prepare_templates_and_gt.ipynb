{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-07-23T11:09:25.760442Z"
    }
   },
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.pose_extractor import PoseViTExtractor\n",
    "from tools.ply_file_to_3d_coord_model import convert_unique\n",
    "from rendering.renderer_xyz import Renderer\n",
    "from rendering.model import Model3D\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pose_utils import vis_utils\n",
    "from pose_utils import img_utils\n",
    "from rendering.utils import get_rendering, get_sympose\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Test pose estimation inference on test set')\n",
    "parser.add_argument('--config_file', default=\"./zs6d_configs/template_gt_preparation_configs/cfg_template_gt_generation_ycbv.json\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "with open(os.path.join(args.config_file),'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "with open(os.path.join(config['path_models_info_json']), 'r') as f:\n",
    "    models_info = json.load(f)\n",
    "\n",
    "obj_poses = np.load(config['path_template_poses'])\n",
    "\n",
    "# Creating the output folder for the cropped templates and descriptors\n",
    "if not os.path.exists(config['path_output_templates_and_descs_folder']):\n",
    "    os.makedirs(config['path_output_templates_and_descs_folder'])\n",
    "\n",
    "# Creating the models_xyz folder\n",
    "if not os.path.exists(config['path_output_models_xyz']):\n",
    "    os.makedirs(config['path_output_models_xyz'])\n",
    "\n",
    "# Preparing the object models in xyz format:\n",
    "print(\"Loading and preparing the object meshes:\")\n",
    "norm_factors = {}\n",
    "for obj_model_name in tqdm(os.listdir(config['path_object_models_folder'])):\n",
    "    if obj_model_name.endswith(\".ply\"):\n",
    "        obj_id = int(obj_model_name.split(\"_\")[-1].split(\".ply\")[0])\n",
    "        input_model_path = os.path.join(config['path_object_models_folder'], obj_model_name)\n",
    "        output_model_path = os.path.join(config['path_output_models_xyz'], obj_model_name)\n",
    "        # if not os.path.exists(output_model_path):\n",
    "        x_abs,y_abs,z_abs,x_ct,y_ct,z_ct = convert_unique(input_model_path, output_model_path)\n",
    "\n",
    "        norm_factors[obj_id] = {'x_scale':float(x_abs),\n",
    "                                'y_scale':float(y_abs),\n",
    "                                'z_scale':float(z_abs),\n",
    "                                'x_ct':float(x_ct),\n",
    "                                'y_ct':float(y_ct),\n",
    "                                'z_ct':float(z_ct)}\n",
    "\n",
    "with open(os.path.join(config['path_output_models_xyz'],\"norm_factor.json\"),\"w\") as f:\n",
    "    json.dump(norm_factors,f)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "extractor = PoseViTExtractor(model_type='dino_vits8', stride=4, device=device)\n",
    "\n",
    "cam_K = np.array(config['cam_K']).reshape((3,3))\n",
    "\n",
    "ren = Renderer((config['template_resolution'][0], config['template_resolution'][1]), cam_K)\n",
    "\n",
    "template_labels_gt = dict()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for template_name in tqdm(os.listdir(config['path_templates_folder'])):\n",
    "\n",
    "        path_template_folder = os.path.join(config['path_templates_folder'], template_name)\n",
    "\n",
    "        if os.path.isdir(path_template_folder) and template_name != \"models\" and template_name != \"models_proc\":\n",
    "\n",
    "            path_to_template_desc = os.path.join(config['path_output_templates_and_descs_folder'],\n",
    "                                                 template_name)\n",
    "\n",
    "            if not os.path.exists(path_to_template_desc):\n",
    "                os.makedirs(path_to_template_desc)\n",
    "\n",
    "            obj_id = template_name.split(\"_\")[-1]\n",
    "\n",
    "            model_info = models_info[str(obj_id)]\n",
    "\n",
    "            obj_model = Model3D()\n",
    "            model_path = os.path.join(config['path_output_models_xyz'], f\"obj_{int(obj_id):06d}.ply\")\n",
    "\n",
    "            # Some objects are scaled inconsistently within the dataset, these exceptions are handled here:\n",
    "            obj_scale = config['obj_models_scale']\n",
    "            obj_model.load(model_path, scale=obj_scale)\n",
    "\n",
    "            files = os.listdir(path_template_folder)\n",
    "            filtered_files = list(filter(lambda x: not x.startswith('mask_'), files))\n",
    "            filtered_files.sort(key=lambda x: os.path.getmtime(os.path.join(path_template_folder,x)))\n",
    "\n",
    "            tmp_list = []\n",
    "\n",
    "            for i, file in enumerate(filtered_files):\n",
    "\n",
    "                # Preparing mask and bounding box [x,y,w,h]\n",
    "                mask_path = os.path.join(path_template_folder, f\"mask_{file}\")\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                x, y, w, h = cv2.boundingRect(contours[0])\n",
    "                crop_size = max(w,h)\n",
    "\n",
    "                # Preparing cropped image and desc\n",
    "                img = cv2.imread(os.path.join(path_template_folder, file))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_crop, crop_x, crop_y = img_utils.make_quadratic_crop(img, [x, y, w, h])\n",
    "                img_prep, img_crop, _ = extractor.preprocess(Image.fromarray(img_crop), load_size=224)\n",
    "                desc = extractor.extract_descriptors(img_prep.to(device), layer=11, facet='key', bin=False, include_cls=True)\n",
    "                desc = desc.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "                R = obj_poses[i][:3,:3]\n",
    "                t = obj_poses[i].T[-1,:3]\n",
    "                sym_continues = [0,0,0,0,0,0]\n",
    "                keys = model_info.keys()\n",
    "\n",
    "                if('symmetries_continuous' in keys):\n",
    "                    sym_continues[:3] = model_info['symmetries_continuous'][0]['axis']\n",
    "                    sym_continues[3:] = model_info['symmetries_continuous'][0]['offset']\n",
    "                \n",
    "                rot_pose, rotation_lock = get_sympose(R, sym_continues)                 \n",
    "                \n",
    "                img_uv, depth_rend, bbox_template = get_rendering(obj_model, rot_pose, t/1000., ren)\n",
    "\n",
    "                img_uv = img_uv.astype(np.uint8)\n",
    "\n",
    "                img_uv,_,_ = img_utils.make_quadratic_crop(img_uv, [crop_y, crop_x, crop_size, crop_size])\n",
    "\n",
    "\n",
    "                # Storing template information:\n",
    "                tmp_dict = {\"img_id\": str(i),\n",
    "                            \"img_name\":os.path.join(os.path.join(path_template_folder,file)),\n",
    "                            \"mask_name\":os.path.join(os.path.join(path_template_folder,f\"mask_{file}\")),\n",
    "                            \"obj_id\": str(obj_id),\n",
    "                            \"bbox_obj\": [x,y,w,h],\n",
    "                            \"cam_R_m2c\": R.tolist(),\n",
    "                            \"cam_t_m2c\": t.tolist(),\n",
    "                            \"model_path\": os.path.join(config['path_object_models_folder'], f\"obj_{int(obj_id):06d}.ply\"),\n",
    "                            \"model_info\": models_info[str(obj_id)],\n",
    "                            \"cam_K\": cam_K.tolist(),\n",
    "                            \"img_crop\": os.path.join(path_to_template_desc, file),\n",
    "                            \"img_desc\": os.path.join(path_to_template_desc, f\"{file.split('.')[0]}.npy\"),\n",
    "                            \"uv_crop\": os.path.join(path_to_template_desc, f\"{file.split('.')[0]}_uv.npy\"),\n",
    "\n",
    "                }\n",
    "\n",
    "                tmp_list.append(tmp_dict)\n",
    "\n",
    "                # Saving all template crops and descriptors:\n",
    "                np.save(tmp_dict['uv_crop'], img_uv)\n",
    "                np.save(tmp_dict['img_desc'], desc)\n",
    "                img_crop.save(tmp_dict['img_crop'])\n",
    "\n",
    "\n",
    "            template_labels_gt[str(obj_id)] = tmp_list\n",
    "\n",
    "with open(config['output_template_gt_file'], 'w') as f:\n",
    "    json.dump(template_labels_gt, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:09:26.589022Z",
     "start_time": "2024-07-23T11:09:26.588693Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2e3b1ae9ba854194",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dad9a16d611606f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41b6801b0471ce26"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
